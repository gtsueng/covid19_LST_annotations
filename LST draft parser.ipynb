{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "from pandas import read_csv\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create curatedBy Object\n",
    "def generate_curator():\n",
    "    todate = datetime.now()\n",
    "    curatedByObject = {\"@type\": \"Organization\", \"identifier\": \"covid19LST\", \"url\": \"https://www.covid19lst.org/\", \n",
    "                              \"name\": \"COVID-19 Literature Surveillance Team\", \"affiliation\": \"\", \n",
    "                              \"curationDate\": todate.strftime(\"%Y-%m-%d\")}\n",
    "    return(curatedByObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_missing(missing):\n",
    "    try:\n",
    "        missing_list = pickle.load(open('results/pubs_not_yet_in_outbreak.txt','rb'))\n",
    "        if missing != None:\n",
    "            total_missing = list(set([*missing_list, *missing]))\n",
    "            with open('results/pubs_not_yet_in_outbreak.txt','wb') as dmpfile:\n",
    "                pickle.dump(total_missing,dmpfile)\n",
    "    except:\n",
    "        if missing != None:\n",
    "            with open('results/pubs_not_yet_in_outbreak.txt','wb') as dmpfile:\n",
    "                pickle.dump(total_missing,dmpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note that this script to be revised after the COVID19 LST reports are added to the outbreak.info database\n",
    "#### The API can then be used to create the table associated each report to each PMID \n",
    "#### by querying the API for COVID19 LST reports and their 'isBasedOn' field\n",
    "\n",
    "def generated_citedBy_dict():\n",
    "    txtdmp = read_csv('results/update dumps/litcovid_citedBy.tsv', delimiter='\\t', header=0, index_col=0)\n",
    "    dictlist = []\n",
    "    for i in range(len(txtdump)):\n",
    "        tmpdict={'_id':txtdump.iloc[i]['_id'],'citedBy':[{'@type':'Publication',\n",
    "                                                                'identifier':txtdump.iloc[i]['identifier'],\n",
    "                                                                'name':txtdump.iloc[i]['name'],\n",
    "                                                                'url':txtdump.iloc[i]['url']}]}\n",
    "        dictlist.append(tmpdict)\n",
    "    with open('results/update dumps/litcovid_citedBy.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(dictlist, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download CSVs from google drive\n",
    "\n",
    "https://drive.google.com/drive/folders/1603ahBNdt1SnSaYYBE-G8SA6qgRTQ6fF\n",
    "\n",
    "Note that the covid19 LST dumps will be update dumps rather than whole database dumps in order to minimize their file size (and upload time) as whole dumps will get progressively larger and take longer to upload.\n",
    "\n",
    "Note that this script uses the googledrive api which requires authentification even when accessing a public google drive. To fulfill this requirement without needing to manually log in, credentials from a service account are needed  The googledrive API is only used to read the files in the drive so that the newest ones (by date) can be identified, and their id's taken.\n",
    "\n",
    "Additionally the the pydrive2 library (use to access the google drive api) sometimes has trouble finding the client_secrets.json file, so you may need to manually point to it.\n",
    "\n",
    "The downloader uses the GoogleDriveDownloader library which is based off of requests and should not require the google drive api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function identifies files uploaded after 2020.09.11 that have NOT yet been downloaded\n",
    "## Note that this is the function if a service account is not available. It requires a login\n",
    "\n",
    "def check_google():\n",
    "    from pydrive2.auth import GoogleAuth\n",
    "    from pydrive2.drive import GoogleDrive\n",
    "\n",
    "    GoogleAuth.DEFAULT_SETTINGS['client_config_file'] = 'client_secrets.json' ##point to secrets file location\n",
    "    gauth = GoogleAuth()\n",
    "    #gauth.LocalWebserverAuth()\n",
    "\n",
    "    drive = GoogleDrive(gauth)\n",
    "    file_id = '1603ahBNdt1SnSaYYBE-G8SA6qgRTQ6fF'\n",
    "    file_list = drive.ListFile({'q': \"'%s' in parents and trashed=false\" % file_id}).GetList()\n",
    "    \n",
    "    df = pandas.DataFrame(file_list)\n",
    "    dfclean = df[['createdDate','id','title']].copy()\n",
    "    dfclean['date'] = pandas.to_datetime(dfclean['createdDate'],format='%Y-%m-%d', errors='coerce')\n",
    "    lastupdate = dfclean.loc[dfclean['createdDate']=='2020-09-11T01:53:29.639Z'].iloc[0]['date']\n",
    "    dfnew = dfclean.loc[dfclean['date']>lastupdate]\n",
    "    \n",
    "    all_files = os.listdir('data/reports/')\n",
    "    new_files = [item  for item in all_files if item not in dfnew['title'].unique().tolist()]\n",
    "    reportdf = dfnew.loc[dfnew['title'].isin(new_files)]\n",
    "    return(reportdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         kind                                 id                  etag  \\\n",
      "0  drive#file  1EyccnGO2UOun668cv4ddE6kg4jggm31J  \"MTYwMDQ0OTE5MTAwMA\"   \n",
      "1  drive#file  1fxpNQRGhg8UNBIzSEBDKD0m-DjSB-1fE  \"MTYwMDM5NDk3MDAwMA\"   \n",
      "\n",
      "                                            selfLink  \\\n",
      "0  https://www.googleapis.com/drive/v2/files/1Eyc...   \n",
      "1  https://www.googleapis.com/drive/v2/files/1fxp...   \n",
      "\n",
      "                                      webContentLink  \\\n",
      "0  https://drive.google.com/uc?id=1EyccnGO2UOun66...   \n",
      "1  https://drive.google.com/uc?id=1fxpNQRGhg8UNBI...   \n",
      "\n",
      "                                       alternateLink  \\\n",
      "0  https://drive.google.com/file/d/1EyccnGO2UOun6...   \n",
      "1  https://drive.google.com/file/d/1fxpNQRGhg8UNB...   \n",
      "\n",
      "                                           embedLink  \\\n",
      "0  https://drive.google.com/file/d/1EyccnGO2UOun6...   \n",
      "1  https://drive.google.com/file/d/1fxpNQRGhg8UNB...   \n",
      "\n",
      "                                            iconLink  \\\n",
      "0  https://drive-thirdparty.googleusercontent.com...   \n",
      "1  https://drive-thirdparty.googleusercontent.com...   \n",
      "\n",
      "                                       thumbnailLink  \\\n",
      "0  https://lh3.googleusercontent.com/bgcvSn-sQnnH...   \n",
      "1  https://lh3.googleusercontent.com/HW2RXRkoSq2F...   \n",
      "\n",
      "                                    title  ...  \\\n",
      "0  20200918 The COVID-19 Daily Report.pdf  ...   \n",
      "1  20200917 The COVID-19 Daily Report.pdf  ...   \n",
      "\n",
      "                          capabilities editable  copyable writersCanShare  \\\n",
      "0  {'canCopy': True, 'canEdit': False}    False      True            True   \n",
      "1  {'canCopy': True, 'canEdit': False}    False      True            True   \n",
      "\n",
      "  shared explicitlyTrashed appDataContents  \\\n",
      "0   True             False           False   \n",
      "1   True             False           False   \n",
      "\n",
      "                                      headRevisionId   spaces exportLinks  \n",
      "0  0Bz4ifkSdU_1dU3FJZGFuN0xKRml6YWl4TEZUN3YvU0pZW...  [drive]         NaN  \n",
      "1  0B0FA6-NbD0WZVUVnWlFFNUhseFhXQjNFcU5LVXVFNnJFL...  [drive]         NaN  \n",
      "\n",
      "[2 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "## This function identifies files uploaded after 2020.09.11 that have NOT yet been downloaded\n",
    "## Note that this is the function if a service account IS available. \n",
    "def check_google():\n",
    "    from pydrive2.auth import GoogleAuth\n",
    "    from pydrive2.drive import GoogleDrive\n",
    "    from pydrive2.auth import ServiceAccountCredentials\n",
    "    \n",
    "    gauth = GoogleAuth()\n",
    "    scope = ['https://www.googleapis.com/auth/drive']\n",
    "    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)\n",
    "    drive = GoogleDrive(gauth)\n",
    "    file_id = '1603ahBNdt1SnSaYYBE-G8SA6qgRTQ6fF'\n",
    "    file_list = drive.ListFile({'q': \"'%s' in parents and trashed=false\" % file_id}).GetList()\n",
    "    \n",
    "    df = pandas.DataFrame(file_list)\n",
    "    dfclean = df[['createdDate','id','title']].copy()\n",
    "    dfclean['date'] = pandas.to_datetime(dfclean['createdDate'],format='%Y-%m-%d', errors='coerce')\n",
    "    lastupdate = dfclean.loc[dfclean['createdDate']=='2020-09-11T01:53:29.639Z'].iloc[0]['date']\n",
    "    dfnew = dfclean.loc[dfclean['date']>lastupdate]\n",
    "    \n",
    "    all_files = os.listdir('data/reports/')\n",
    "    new_files = [item  for item in all_files if item not in dfnew['title'].unique().tolist()]\n",
    "    reportdf = dfnew.loc[dfnew['title'].isin(new_files)]\n",
    "    return(reportdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the function to actually conduct the download\n",
    "def download_dumps(dumpdf):\n",
    "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "    for i in range(len(dumpdf)):\n",
    "        title = dumpdf.iloc[i]['title']\n",
    "        eachid = dumpdf.iloc[i]['id']\n",
    "        gdd.download_file_from_google_drive(file_id=eachid,\n",
    "                                            dest_path='data/table/'+title,\n",
    "                                            unzip=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the data dump\n",
    "\n",
    "Note that this code still needs a downloader to pull data from either github or google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_keywords(keywordstring):\n",
    "    if keywordstring != keywordstring: ## Is it Nan?\n",
    "        keywordlist = []\n",
    "    elif keywordstring ==\"\": ## Is it an empty string?\n",
    "        keywordlist = []\n",
    "    elif keywordstring == None: ## Is there no keywordstring?\n",
    "        keywordlist = []\n",
    "    else:\n",
    "        keywordlist = keywordstring.lstrip('[').rstrip(']').replace('\"','').split(',')\n",
    "    return(keywordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lst_dump(datadmp):\n",
    "    cleandata = []\n",
    "    authorObject = generate_curator()\n",
    "    datadmp['_id'] = 'pmid'+datadmp['PMID'].astype(str)  \n",
    "    for i in range(len(datadmp)):\n",
    "        keywordlist = fix_keywords(datadmp.iloc[i]['Topics'])\n",
    "        tmpdict={'_id':datadmp.iloc[i]['_id'],'keywords':keywordlist,\n",
    "                 'covid19LST':{'@type':'Rating',\n",
    "                                 'ratingExplanation':datadmp.iloc[i]['Methodology'],\n",
    "                                 'ratingValue':datadmp.iloc[i]['LevelOfEvidence'],\n",
    "                                 'reviewAspect':'Oxford 2011 Levels of Evidence',\n",
    "                                 'author':authorObject}}\n",
    "        cleandata.append(tmpdict)\n",
    "    return(cleandata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_filelist():\n",
    "    all_files = os.listdir('data/tables/')\n",
    "    updatefiles = all_files.remove('covid19LST_1st_dump.csv')\n",
    "    initial_file = 'data/tables/covid19LST_1st_dump.csv'\n",
    "    df = read_csv(initial_file,header=0,usecols=['PMID','Topics','LevelOfEvidence','Methodology','Updated Date'])\n",
    "    if updatefiles!=None:\n",
    "        for eachfile in updatefiles:\n",
    "            tmpfile = read_csv('data/tables/'+eachfile,header=0,usecols=['PMID','Topics','LevelOfEvidence','Methodology','Updated Date'])\n",
    "            df = pandas.concat((df,tmpfile),ignore_index=True)\n",
    "    else:\n",
    "        nochange=True\n",
    "    df.sort_values('Updated Date',ascending=False,inplace=True)\n",
    "    df.drop_duplicates(subset='PMID',keep='first',inplace=True)\n",
    "    return(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run an update\n",
    "\n",
    "def run_loe_update():\n",
    "    datadmp = update_filelist()\n",
    "    dictlist = generate_lst_dump(datadmp)\n",
    "    with open('results/update_dumps/lst_loe_annotations.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(dictlist, indent=4))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loe_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
